{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cfb7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path = r\"database.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split features and target variables\n",
    "X = df.drop([''], axis=1)  \n",
    "y = df['']  \n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,  y,  test_size=0.2,  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95849aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# XGBoost parameters\n",
    "params_xgb = {\n",
    "    'booster': 'gbtree',              # Boosting method, here using Gradient Boosting Tree.\n",
    "    'objective': 'reg:squarederror',  # Loss function, here using squared error, which is suitable for regression tasks.\n",
    "    'max_leaves': 127,                # The number of leaf nodes per tree, which controls the model complexity.\n",
    "    'verbosity': 1,                   # The verbosity of XGBoost's output. 0 indicates no output, while 1 indicates outputting progress information.\n",
    "    'seed': 42,                       # Random seed, used to reproduce the model's results.\n",
    "    'nthread': -1,                    # The number of threads for parallel computation, where -1 indicates using all available CPU cores.\n",
    "    'colsample_bytree': 0.6,          # The proportion of features randomly selected for each tree, used to enhance the model's generalization ability.\n",
    "    'subsample': 0.7,                 # The proportion of samples randomly selected in each iteration, used to enhance the model's generalization ability.\n",
    "    'eval_metric': 'rmse'             # Evaluation metric, here using RMSE.\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize the XGBoost classification model\n",
    "model_xgb = xgb.XGBRegressor(**params_xgb)\n",
    "\n",
    "\n",
    "# Define a parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],  # Tree number\n",
    "    'max_depth': [3, 4, 5, 6, 7],               # Tree depth\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1],   # Learning rate\n",
    "}\n",
    "\n",
    "\n",
    "# Use GridSearchCV for grid search and k-fold cross-validation.\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Evaluation metric is negative MSE.\n",
    "    cv=10,                              # 10-fold cross-validation.\n",
    "    n_jobs=-1,                         # Parallel computing.\n",
    "    verbose=1                          # Output detailed progress information.\n",
    ")\n",
    "\n",
    "# Model training\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model_xgboost = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(best_model_xgboost)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_df = pd.DataFrame(shap_values, columns=X_test.columns)\n",
    "shap_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the absolute values of each column\n",
    "mean_abs_shap_values = shap_values_df.abs().mean()\n",
    "shap_values_with_mean = shap_values_df.copy()  \n",
    "shap_values_with_mean.columns = [f\"{col} ({mean_abs_shap_values[col]:.3f})\" for col in shap_values_with_mean.columns]\n",
    "shap_values_with_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3503e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test, feature_names=shap_values_with_mean.columns, plot_type=\"dot\", show=False)\n",
    "plt.savefig(\"Total effects.pdf\", format='pdf',bbox_inches='tight',dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab93fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP interaction values\n",
    "# Extract the diagonal elements to represent the main effect values\n",
    "shap_interaction_values = explainer.shap_interaction_values(X_test) \n",
    "main_effects = np.array([shap_interaction_values[:, i, i] for i in range(shap_interaction_values.shape[1])]).T\n",
    "main_effects_df = pd.DataFrame(main_effects, columns=X_test.columns)\n",
    "main_effects_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe250ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the absolute values of each column\n",
    "mean_abs_shap_vaMain_effects = main_effects_df.abs().mean()\n",
    "shap_values_with_mean_vaMain_effects = main_effects_df.copy()  \n",
    "shap_values_with_mean_vaMain_effects.columns = [f\"{col} ({mean_abs_shap_vaMain_effects[col]:.3f})\" for col in shap_values_with_mean_vaMain_effects.columns]\n",
    "shap_values_with_mean_vaMain_effects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4712682",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.summary_plot(np.array(main_effects_df), X_test, feature_names=shap_values_with_mean_vaMain_effects.columns, plot_type=\"dot\", show=False)\n",
    "plt.xlabel('Main effect SHAP')\n",
    "plt.savefig(\"vaMain effects.pdf\", format='pdf',bbox_inches='tight',dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d08603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Name\n",
    "feature_names = X_test.columns\n",
    "\n",
    "# Initialize an empty DataFrame, a matrix of size equal to the number of features\n",
    "interaction_matrix = pd.DataFrame(np.nan, index=feature_names, columns=feature_names)\n",
    "\n",
    "# Traversing each pair of features\n",
    "for i, feature in enumerate(feature_names):\n",
    "    for j, other_feature in enumerate(feature_names):\n",
    "        if i != j:  # Consider only the interactions between different features\n",
    "            # Calculate the absolute value of each sample's SHAP interaction value\n",
    "            interaction_values = [shap_interaction_values[sample_idx][i, j] for sample_idx in range(shap_interaction_values.shape[0])]\n",
    "            # Calculate the average absolute value of interaction values\n",
    "            avg_interaction_value = np.mean(np.abs(interaction_values))\n",
    "            # Assign the result to the corresponding matrix \n",
    "            interaction_matrix.loc[feature, other_feature] = avg_interaction_value\n",
    "        else:\n",
    "            # Calculate the main effect values (values on the diagonal)\n",
    "            main_effect_values = [shap_interaction_values[sample_idx][i, i] for sample_idx in range(shap_interaction_values.shape[0])]\n",
    "            # Calculate the average absolute value of main effect values\n",
    "            avg_main_effect_value = np.mean(np.abs(main_effect_values))\n",
    "            # Assign the main effect values to the diagonal positions\n",
    "            interaction_matrix.loc[feature, feature] = avg_main_effect_value\n",
    "\n",
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = interaction_matrix.columns\n",
    "main_effect_values = np.diag(interaction_matrix)\n",
    "# Sort the main effect values from high to low\n",
    "sorted_effects = sorted(zip(features, main_effect_values), key=lambda x: x[1], reverse=True)\n",
    "# Extract the sorted feature names and main effect values\n",
    "sorted_features, sorted_main_effect_values = zip(*sorted_effects)\n",
    "# Create an empty matrix to store the interaction effect values\n",
    "interaction_values_matrix = np.zeros((len(features), len(features)))\n",
    "\n",
    "# Fill the interaction effect matrix, considering only non-diagonal elements (interaction effects)\n",
    "for i, feature in enumerate(features):\n",
    "    for j, other_feature in enumerate(features):\n",
    "        if i != j:  # Consider only the interaction effects of off-diagonals\n",
    "            interaction_values_matrix[i, j] = interaction_matrix.iloc[i, j]*2\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "index = np.arange(len(sorted_features))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.bar(index - bar_width / 2, sorted_main_effect_values, bar_width, label=\"Main Effect\", color=\"#FFFF00\",alpha=0.8)\n",
    "\n",
    "bars_data = interaction_values_matrix.T  # Transpose, for easier stacking.\n",
    "bottom = np.zeros(len(features))  # Used as the base for stacking.\n",
    "\n",
    "# Draw an interaction effect stacked bar chart (right)\n",
    "for i in range(len(features)):\n",
    "    # Plot each stacked component.\n",
    "    bars = plt.bar(index + bar_width / 2, bars_data[i], bar_width, bottom=bottom, label=f'Interaction with {features[i]}')\n",
    "    bottom += bars_data[i]  \n",
    "\n",
    "# Display the total sum of the stack at the top of the stacked bar chart\n",
    "for i in range(len(features)):\n",
    "    total_height = np.sum(bars_data[:, i])  # Calculate the sum of each column\n",
    "    if total_height > 0:\n",
    "        plt.text(index[i] + bar_width / 2, bottom[i], f'{total_height:.3f}', ha='center', va='bottom', fontsize=13)\n",
    "\n",
    "plt.xticks(index, sorted_features, ha='center')\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Mean Absolute SHAP Values\", fontsize=14)\n",
    "plt.title(\"\")\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "for i, rect in enumerate(plt.gca().patches[:len(sorted_features)]):\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width() / 2, height, f'{height:.3f}', ha='center', va='bottom', fontsize=13)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.3), ncol=3, fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Main and Interaction Effects.pdf\", format='pdf',bbox_inches='tight',dpi=1200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
