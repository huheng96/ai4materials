{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8559541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(r\"\")\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a777600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training set and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6843be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# XGBoost parameters\n",
    "params_xgb = {\n",
    "    'booster': 'gbtree',              # Boosting method, here using Gradient Boosting Tree.\n",
    "    'objective': 'reg:squarederror',  # Loss function, here using squared error, which is suitable for regression tasks.\n",
    "    'max_leaves': 127,                # The number of leaf nodes per tree, which controls the model complexity.\n",
    "    'verbosity': 1,                   # The verbosity of XGBoost's output. 0 indicates no output, while 1 indicates outputting progress information.\n",
    "    'seed': 42,                       # Random seed, used to reproduce the model's results.\n",
    "    'nthread': -1,                    # The number of threads for parallel computation, where -1 indicates using all available CPU cores.\n",
    "    'colsample_bytree': 0.6,          # The proportion of features randomly selected for each tree, used to enhance the model's generalization ability.\n",
    "    'subsample': 0.7,                 # The proportion of samples randomly selected in each iteration, used to enhance the model's generalization ability.\n",
    "    'eval_metric': 'rmse'             # Evaluation metric, here using RMSE.\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize the XGBoost classification model\n",
    "model_xgb = xgb.XGBRegressor(**params_xgb)\n",
    "\n",
    "\n",
    "# Define a parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],  # Tree number\n",
    "    'max_depth': [3, 4, 5, 6, 7],               # Tree depth\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1],   # Learning rate\n",
    "}\n",
    "\n",
    "\n",
    "# Use GridSearchCV for grid search and k-fold cross-validation.\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Evaluation metric is negative MSE.\n",
    "    cv=10,                              # 10-fold cross-validation.\n",
    "    n_jobs=-1,                         # Parallel computing.\n",
    "    verbose=1                          # Output detailed progress information.\n",
    ")\n",
    "\n",
    "# Model training\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model_xgboost = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ffa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(best_model_xgboost)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap_values_df = pd.DataFrame(shap_values, columns=X.columns)\n",
    "shap_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dependence plot\n",
    "shap.dependence_plot(\n",
    "    'ST', \n",
    "    shap_values, \n",
    "    X, \n",
    "    interaction_index=None,  \n",
    "    show=False\n",
    ")\n",
    "plt.savefig(\"6.png\", format='png', bbox_inches='tight', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dependence plot\n",
    "shap.dependence_plot(\n",
    "    'TC', \n",
    "    shap_values, \n",
    "    X, \n",
    "    interaction_index=None,  \n",
    "    show=False\n",
    ")\n",
    "plt.savefig(\"6.png\", format='png', bbox_inches='tight', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1303f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dependence plot\n",
    "shap.dependence_plot(\n",
    "    'TOT', \n",
    "    shap_values, \n",
    "    X, \n",
    "    interaction_index=None,  \n",
    "    show=False\n",
    ")\n",
    "plt.savefig(\"6.png\", format='png', bbox_inches='tight', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d23d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pygam import LinearGAM, s\n",
    "\n",
    "\n",
    "# Construct GAM Mpdel\n",
    "X1 = X['ST'].values.reshape(-1, 1)  # The input to a GAM must be two-dimensional.\n",
    "y1 = shap_values_df['ST'].values\n",
    "\n",
    "gam = LinearGAM(s(0)).fit(X1, y1)  # Smooth fitting for the single feature.\n",
    "\n",
    "# Generate grid points for X (feature space) and predict SHAP values along with confidence intervals.\n",
    "XX = gam.generate_X_grid(term=0)\n",
    "y_pred = gam.predict(XX)\n",
    "confidence_interval = gam.prediction_intervals(XX, width=0.95)  # 95% confidence interval\n",
    "\n",
    "# Plot the GAM fitting curve and confidence interval.\n",
    "plt.figure(figsize=(6, 4), dpi=1200)\n",
    "\n",
    "# Plot the trend line (blue solid line)\n",
    "plt.plot(XX, y_pred, color=\"blue\", linewidth=2, label=\"Trend (GAM)\")\n",
    "\n",
    "# Plot the confidence interval (blue shaded area)\n",
    "plt.fill_between(\n",
    "    XX.flatten(),\n",
    "    confidence_interval[:, 0],  # Lower confidence bound.\n",
    "    confidence_interval[:, 1],  # Upper confidence bound.\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    "    label=\"95% CI\"\n",
    ")\n",
    "\n",
    "# Add a horizontal line at shap=0.\n",
    "plt.axhline(y=0, color='black', linestyle='-.', linewidth=1)\n",
    "\n",
    "# Axe settings\n",
    "plt.xlabel('ST', fontsize=12)\n",
    "plt.ylabel('SHAP value', fontsize=12)\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Save figure\n",
    "plt.savefig(\"1.png\", format='png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X['ST'].values.reshape(-1, 1)  \n",
    "y = shap_values_df['ST'].values\n",
    "\n",
    "# Construct GAM Model\n",
    "gam = LinearGAM(s(0)).fit(X, y)  # Univariate Smoothing\n",
    "\n",
    "# Univariate Smoothing\n",
    "XX = gam.generate_X_grid(term=0, n=1000)  #  Grid points of X\n",
    "y_pred = gam.predict(XX)  # Predicted values from GAM fitting\n",
    "confidence_interval = gam.prediction_intervals(XX, width=0.95)  # Confidence Interval\n",
    "\n",
    "# Extract R-squared\n",
    "R2 = gam.statistics_['pseudo_r2']['explained_deviance'] * 100  # Extract the explained deviance and convert it to a percentage\n",
    "\n",
    "# Find all intersection points between y=0 and the fitted line\n",
    "zero_crossing_indices = np.where(np.diff(np.sign(y_pred)))[0]\n",
    "\n",
    "# Calculate the filling range\n",
    "y_min, y_max = y_pred.min() - 0.05, y_pred.max() + 0.05\n",
    "\n",
    "# Plot figure\n",
    "plt.figure(figsize=(6, 4), dpi=1200)\n",
    "\n",
    "# Plot y=0（Gris dotted line）\n",
    "plt.axhline(y=0, color='gray', linestyle='--', linewidth=1, zorder=0)\n",
    "\n",
    "# Plot the confidence interval (dashed line, color #ABDAFC)\n",
    "plt.plot(XX, confidence_interval[:, 0], color=\"#9FD4AE\", linestyle=\"--\", linewidth=1, zorder=2)\n",
    "plt.plot(XX, confidence_interval[:, 1], color=\"#9FD4AE\", linestyle=\"--\", linewidth=1, zorder=2)\n",
    "\n",
    "# Plot the trend line (solid line, color #6A9ACF)\n",
    "plt.plot(XX, y_pred, color=\"#6A9ACF\", linewidth=2, zorder=3)\n",
    "\n",
    "# If intersection points exist, plot gray vertical lines and dots\n",
    "if len(zero_crossing_indices) > 0:\n",
    "    for idx in zero_crossing_indices:\n",
    "        tipping_point_x = XX[idx]\n",
    "        tipping_point_y = y_pred[idx]\n",
    "        plt.axvline(x=tipping_point_x, color='gray', linestyle='--', linewidth=1, zorder=1)\n",
    "        plt.scatter(tipping_point_x, tipping_point_y, color='red', zorder=4)\n",
    "    \n",
    "    # Add the label \"Tipping Point\" at the first intersection point\n",
    "    tipping_point_x = XX[zero_crossing_indices[0]]\n",
    "    tipping_point_y = y_pred[zero_crossing_indices[0]]\n",
    "    plt.text(\n",
    "        tipping_point_x, tipping_point_y + 0.01,\n",
    "        \"Tipping Point\",\n",
    "        fontsize=10,\n",
    "        color=\"red\"\n",
    "    )\n",
    "\n",
    "# Calculate the filled area\n",
    "y_positive = y_pred > 0  # Positive Value Region\n",
    "y_negative = y_pred <= 0  # Negative Value Region\n",
    "\n",
    "# Fill the region where y > 0\n",
    "plt.fill_between(\n",
    "    XX.flatten(),\n",
    "    y_min,\n",
    "    y_max,\n",
    "    where=y_positive.flatten(),\n",
    "    color=\"#FCDFBE\",\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "# Fill the region where y < 0\n",
    "plt.fill_between(\n",
    "    XX.flatten(),\n",
    "    y_min,\n",
    "    y_max,\n",
    "    where=y_negative.flatten(),\n",
    "    color=\"#ABDAFC\",\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "#  The P-value is obtained from gam.statistics_\n",
    "P_value = gam.statistics_['p_values'][0]  \n",
    "\n",
    "# Set the display content according to the P-value range\n",
    "if P_value < 0.001:\n",
    "    P_text = r\"$\\mathit{p < 0.001}$\"  \n",
    "elif P_value < 0.05:\n",
    "    P_text = r\"$\\mathit{p < 0.05}$\"  \n",
    "else:\n",
    "    P_text = r\"$\\mathit{p > 0.05}$\"  \n",
    "\n",
    "# Add the fit to the bottom-right corner, and display the P-value description below it.\n",
    "plt.text(\n",
    "    XX.min() + 0.1 * (XX.max() - XX.min()),\n",
    "    y_min + 0.1 * (y_max - y_min),\n",
    "    f\"$R^2={R2:.2f}\\%$\\n{P_text}\",  \n",
    "    fontsize=10,\n",
    "    color=\"black\"\n",
    ")\n",
    "\n",
    "# Axe settings\n",
    "plt.xlabel('ST', fontsize=12)\n",
    "plt.ylabel('SHAP value', fontsize=12)\n",
    "plt.xlim(XX.min(), XX.max())\n",
    "plt.ylim(y_min, y_max)\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "plt.savefig(\"5.png\", format='png', bbox_inches='tight')\n",
    "\n",
    "# Show figure\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sissopp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
